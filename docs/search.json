[
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Random walks are a commonly used tool in the arsenal of algorithms on Classical Computers to solve a variety of problems which do not have a known easy solution. The power of such methods can be attributed to the fact that while the space of possible solutions is vast, we only need to sample few solutions to come to a close solution. This power has been routinely exploited in the past to sample from Markov Chains using the MCMC algorithm which can be found in any introductory textbook1 of Markov processes, and they have recently been used in the fields of Financial engineering2, fluid mechanics3, fitting black hole images4 and most famously in the Los Alamos project5.\nWith the advent of quantum algorithms, quantum walks have arisen as an obvious extension of classical walks in the quantum domain. The applications of quantum walks are just as many: ANN training6, Random Number Generation7, List coloring (Grover)8, collision finding9, link prediction10. There has even been a recent foray into classifying and using a quantum-classical walk to speed up certain classical algorithms, namely the Google PageRank Algorithm11. The increased interest in quantum walks can be attributed to the quadratic speed up which it grants the solution a-la the Grover algorithm, which itself can be considered as a Quantum Walk12.\nIn this master thesis, we will first define the classical (Chapter 1) walk, and specifically, the 1D walk. The classical 1D walk has a standard deviation which goes as \\(\\mathcal{O}(T^{1/2})\\), and is recurrent.\nThen we define quantum (Chapter 2) walk, particularly the coined walk on a 1D grid. The quantum 1D walk has a standard deviation which goes as \\(\\mathcal{O}(T)\\), and is transient.\nWe define these walks with a view of using these walks in search algorithms. We formalise the search problem and show how the quantum walk is faster but its transient nature leads to a non zero asymptotic failure rate in Chapter 3.\nThen, we look at previous attempts at solving them by resetting (Chapter 4). By resetting a markov chain, we can convert a transient chain to a recurrent one. We explore the effect of resetting in the quantum case, attempting to recreate past work in continuous time quantum walks in the discrete time quantum walks. We also look at possible shortcomings of the solution.\nIn Chapter 5, we introduce a new mechanism for quantum resetting based on superposition of the evolution and reset operations and show numerically that it does not have advantage in the search problem (Chapter 5). However, we propose possible methods to analyze this setup and leave it for a future project.\nFinally, we introduce a second protocol for reset quantum walks by quantizing the Markov process via Szegedy walks (Chapter 6). We also present a Grover like search algorithm, which is easily analyzable by eigenvalue analysis. The results and discussions of this protocol are presented in Chapter 7.\nWe then conclude and provide future directions of this work in the summary\nAlong with the theory, certain aspects of the implementation of the walks computationally are also added as necessary. This is done inline instead of in an appendix, which is the norm, since the author believes that such a presentation solidifies the readers’ understanding of both, the model and the implementation. We use Julia13 and its standard libraries, Plots.jl14, QuantumInformation.jl15, Luxor.jl16, Yao.jl and YaoPlots.jl17.\n\n\n\n\n\n\n1 J.R. Norris, Markov Chains, 1st pbk. ed (Cambridge University Press, Cambridge, UK ; New York, 1998).\n\n\n2 P. Glasserman, Monte Carlo Methods in Financial Engineering (Springer, New York, 2004).\n\n\n3 K.P. Griffin, S.J. Suresh, T.J. Flint, and W.H.R. Chan, (2019).\n\n\n4 D. Psaltis, F. Özel, L. Medeiros, P. Christian, J. Kim, C. Chan, L.J. Conway, C.A. Raithel, D. Marrone, and T.R. Lauer, ApJ 928, 55 (2022).\n\n\n5 N. Metropolis, (n.d.).\n\n\n6 L.S. de Souza, J.H.A. de Carvalho, and T.A.E. Ferreira, in 2019 8th Brazilian Conference on Intelligent Systems ( BRACIS) (IEEE, Salvador, Brazil, 2019), pp. 836–841.\n\n\n7 M. Bae and W.O. Krawec, (2021).\n\n\n8 S. Mukherjee, IEEE Trans. Quantum Eng. 3, 1 (2022).\n\n\n9 X. Bonnetain, A. Chailloux, A. Schrottenloher, and Y. Shen, (2022).\n\n\n10 M. Goldsmith, G. García-Pérez, J. Malmi, M.A.C. Rossi, H. Saarinen, and S. Maniscalco, (2022).\n\n\n11 S.A. Ortega and M.A. Martin-Delgado, (2022).\n\n\n12 Qiskit, Quantum Walk Search Algorithm (n.d.).\n\n\n13 J. Bezanson, A. Edelman, S. Karpinski, and V.B. Shah, SIAM Rev. 59, 65 (2017).\n\n\n14 T. Breloff, (2022).\n\n\n15 P. Gawron, D. Kurzyk, and Ł. Pawela, PLoS ONE 13, e0209358 (2018).\n\n\n16 JuliaGraphics, (n.d.).\n\n\n17 X.-Z. Luo, J.-G. Liu, P. Zhang, and L. Wang, Quantum 4, 341 (2020)."
  },
  {
    "objectID": "classical.html#definition",
    "href": "classical.html#definition",
    "title": "1  Classical Walks",
    "section": "1.1 Definition",
    "text": "1.1 Definition\nConsider an infinite 1 D chain, with nodes marked by \\(\\mathbb{Z}\\).\n\n\n\n\n\nFigure 1.1: 1 D Chain\n\n\n\n\nDefine the probability of hopping from node \\(i\\) to node \\(j\\)\n\\[p_{ij} = \\begin{cases}\n    1/2 & |i - j| = 1 \\\\\n    0 & \\text{otherwise}\n\\end{cases}\\]\nAnd the initial state as\n\\[\\lambda_{ij} = \\begin{cases}\n    1 & i = 0 \\\\\n    0 & \\text{otherwise}\n\\end{cases}\\]\nThus, the hopper can only move to it nearest neighbors, starting from node 0.\nNote that \\(P(X_t = i | \\text{ HISTORY }) = P(X_t = i | X_{t-1})\\), which means that the walk is a Markov chain."
  },
  {
    "objectID": "classical.html#multiple-walkers",
    "href": "classical.html#multiple-walkers",
    "title": "1  Classical Walks",
    "section": "1.2 Multiple Walkers",
    "text": "1.2 Multiple Walkers\nThe SSRW is clearly a stochastic process, and each run of this process will lead to different paths being chosen by the walker, and we are my interested in what the walker does on an average rather than what happens in a particular instance. Thus, we can observe multiple walks, and plot their paths to visualize how they would spread.\nIn order to simulate a walk, we sample \\(X_i \\in \\{-1, 1\\}\\) with equal probability, and add it to the previous position \\(S_{i-1}\\) to get \\(S_i\\). Note \\(S_0 = 0\\). Thus, this is equivalent to sampling from [1, -1] uniformly t times and performing a cumulative sum. For n walkers, we can sample (t, n) such random numbers, and do a cumulative sum along the first dimension.\n\nbm = cumsum(rand([1, -1], (200, 15)), dims=1);\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1.2: An ensemble of classical walkers"
  },
  {
    "objectID": "classical.html#probability-mass-function",
    "href": "classical.html#probability-mass-function",
    "title": "1  Classical Walks",
    "section": "1.3 Probability mass function",
    "text": "1.3 Probability mass function\nAnother common way to visualize the walk is to plot the probability that the walker is on node \\(i\\) at time \\(t\\). For this, we define the transition matrix and \\(\\lambda\\) appropriately and find \\(\\lambda P^t\\). Note however that the transition matrix for the SSRW is Tridiagonal with the Upper and Lower diagonals as 0.5 and the diagonal as 0, and there exist efficient storage and multiplication routines. Also, since we can only store a finite matrix, we limit the walk to some size. At the boundaries, we set open conditions, because this is the easiest to implement.\n\ncps, cps_t = let \n    t = 21\n    U = SymTridiagonal(fill(0., 31), fill(0.5, 30))\n    λ = fill(0., 31)\n    λ[16] = 1\n    ps = accumulate(1:t, init=λ) do old, _\n        U * old\n    end[t÷3:t÷3:t], t÷3\nend;\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1.3: Probability distribution of a classical walker in time"
  },
  {
    "objectID": "classical.html#properties-of-the-walk",
    "href": "classical.html#properties-of-the-walk",
    "title": "1  Classical Walks",
    "section": "1.4 Properties of the walk",
    "text": "1.4 Properties of the walk\nCertain properties of the walk that are interesting for the problem we pose in the subsequent sections. Primarily, we are interested in the mean, standard deviation and recurrence of the graph.\nThe probability that a walker is on node \\(n\\) at time \\(t\\) is given by the expression\n\\[p(n, t) = \\binom{t}{\\frac{t+n}{2}} \\frac{1}{2^t}\\]\nThis equation is valid only if \\(t + n\\) is even and \\(n \\le t\\). If \\(t + n\\) is odd or \\(n &gt; t\\), the probability is zero\nIt should be obvious from the even symmetry of \\(p(n, t)\\) that the mean \\(\\mu(t) = \\sum_n np(n,t) = 0\\). This comes from the fact that the walk is symmetric.\nThe standard deviation of the walker position \\(\\sigma(t) = \\sqrt{\\langle n^2 \\rangle - \\langle n\\rangle^2} = \\sqrt{\\sum_n n^2p(n,t)} = \\sqrt t\\)1.\n\n\n\n\n\n\n1 R. Portugal, Quantum Walks and Search Algorithms, 2nd ed. 2018 (Springer International Publishing : Imprint: Springer, Cham, 2018)."
  },
  {
    "objectID": "quantum.html#introduction",
    "href": "quantum.html#introduction",
    "title": "2  Quantum Walks",
    "section": "2.1 Introduction",
    "text": "2.1 Introduction\nQuantum walks are defined analogous to the classical walks.\nFirst, our walker is quantum mechanical, and the position of the walker can be a superposition of the nodes. Thus, we define the state of the walker to be a superposition of the node states \\(|i\\rangle\\).\n\\[|\\psi\\rangle = \\sum_i c_i|i\\rangle\\]\nLet this Hilbert space be denoted as \\(\\mathcal{H}_W\\). The projection of the state on some node \\(i\\) given by \\(|\\langle i | \\psi\\rangle|^2 = |c_i|^2\\) is understood as the probability that the walker will collapse to the state \\(|i\\rangle\\) on measurement.\nTo define the evolution of the node, we look back at the transition matrix \\(P_{ij}\\). Thus we would define an operation in the following manner -\n\\[O |i\\rangle = \\sum_j \\sqrt{p_{ij}} |j\\rangle\\]\nand the walk proceeds by repeated application of \\(O\\).\nWhile this expression is enough to define the walk, it is not immediately clear how one would explicitly realize such an operation. Multiple formalisms define such walks, but we shall use the coined quantum walk formalism which is very natural for regular graphs, as is the case for the 1D chain. Note that for the symmetric walks on nD lattices, like the 1D chain, the tight-binding model is already a well understood continuous time quantum walk. However, we prefer a discrete time formalism."
  },
  {
    "objectID": "quantum.html#coined-quantum-walk-for-1d-chain",
    "href": "quantum.html#coined-quantum-walk-for-1d-chain",
    "title": "2  Quantum Walks",
    "section": "2.2 Coined Quantum Walk for 1D Chain",
    "text": "2.2 Coined Quantum Walk for 1D Chain\nFor the 1D chain, given a specific node, there are only 2 other nodes connected to it. Thus, we can add a 2 level system, which “decides” which node the walker jumps to. More formally, we attach a 2 level qubit system to the walker whose bases are denoted by \\(|0\\rangle\\) and \\(|1\\rangle\\). Let us denote this Hilbert space as \\(\\mathcal{H}_C\\)\nThus, we can define the shift operation as\n\\[S |0\\rangle|i\\rangle = |0\\rangle|i-1\\rangle; S |1\\rangle|i\\rangle = |1\\rangle|i+1\\rangle\\]\nHow would we define such an operation explicitly?\n\\[S = |0\\rangle\\langle 0|\\otimes S_L + |1\\rangle\\langle 1|\\otimes S_R\\]\nWhere \\(S_L\\) and \\(S_R\\) are defined as\n\\[S_L |i\\rangle = |i-1\\rangle,\\ S_R |i\\rangle = |i+1\\rangle\\]\nNote that \\(S\\) operates on \\(\\mathcal{H}_C\\otimes\\mathcal{H}_W\\), whereas \\(S_L\\) and \\(S_R\\) operate on \\(\\mathcal{H}_W\\) only.\nThe superposition in the two choices at each step is recovered by putting the coin into a superposition of its basis states. This is achieved via a coin operator, which is commonly defined as \\(H\\otimes I\\), where \\(H\\) is the single qubit Hadamard operator.\nLet us explicitly write down two steps of the walk\n\\[H\\otimes I (|0\\rangle |0\\rangle) = \\frac{|0\\rangle |0\\rangle + |1\\rangle |0\\rangle}{\\sqrt 2}\\] \\[S\\left(\\frac{|0\\rangle |0\\rangle + |1\\rangle |0\\rangle}{\\sqrt 2}\\right) = \\frac{|0\\rangle |-1\\rangle + |1\\rangle |1\\rangle}{\\sqrt 2}\\] \\[H\\otimes I \\frac{|0\\rangle |-1\\rangle + |1\\rangle |1\\rangle}{\\sqrt 2} = \\frac{|0\\rangle |-1\\rangle + |1\\rangle |-1\\rangle + |0\\rangle |1\\rangle - |1\\rangle |1\\rangle}{2}\\] \\[S \\frac{|0\\rangle |-1\\rangle + |1\\rangle |-1\\rangle + |0\\rangle |1\\rangle - |1\\rangle |1\\rangle}{2} = \\frac{|0\\rangle |-2\\rangle + (|1\\rangle + |0\\rangle) |0\\rangle - |1\\rangle |2\\rangle}{2}\\]\n\n\n\n\n\n\nRepeated application of Coin Operator\n\n\n\nNote specifically the repeated application of the coin operator. If the coin operator is not applied in step 3, our state will end up in \\(\\frac{1}{\\sqrt{2}} (|0\\rangle|-2\\rangle + |1\\rangle|2\\rangle)\\) which is not what we wanted. This is because the application of the controlled shift operation entangles the coin and the walker systems, and thus there is no superposition in each term of the system"
  },
  {
    "objectID": "quantum.html#computational-implementation",
    "href": "quantum.html#computational-implementation",
    "title": "2  Quantum Walks",
    "section": "2.3 Computational Implementation",
    "text": "2.3 Computational Implementation\nWe show 2 ways to implement the Quantum walks, which are both interesting in their own ways. But the foremost thing to tackle would be how to store an infinite vector and an infinite dimensional operator. Since we cannot do either of these simply, we instead limit our walk to a node space of \\(2n\\), and use periodic boundary conditions.\n\n\n\n\n\n\nOther Boundary Conditions\n\n\n\nOne could pick other boundary conditions too, such as the open or the absorbing boundary conditions, but both of these BCs lead to non-unitary operations, which complicate the definition and application of the gate.\n\n\n\n2.3.1 Matrix formalism\nThe first and more immediate method is to simply write down the matrix equivalent of the above operations. For the visualization of the implementations, we will assume that the walk occurs in a 1 D chain of size 4.\nThe coin is preferred to be in the \\(\\frac{1}{\\sqrt2}(|0\\rangle + i |1\\rangle)\\) when we start so that the walk proceeds symmetrically1.\n\ninit_coin = 1/√2 * (ket(1,2) - 1im * ket(2,2));\n\nThe coin operator is trivial to write,\n\nH = KrausOperators([sparse(hadamard(2)⊗I(4))]);\n\nThe left and right shift operators can be defined in the following manner.\n\nR = collect(Tridiagonal(fill(1., 3), zeros(4), zeros(3)))\nR[1, end] = 1\nL = collect(Tridiagonal(zeros(3), zeros(4), fill(1., 3)))\nL[end, 1] = 1\n\nThus the shift operator is defined as\n\nS = KrausOperators([sparse(proj(ket(1, 2)) ⊗ L + proj(ket(2, 2)) ⊗ R)]);\n\nThus, we can repeatedly apply \\(S\\circ H\\) to the initial state and accumulate the results.\n\ninit_state = proj(init_coin ⊗ ket(2,4))\nψ = [[init_state]; accumulate(1:40, init=init_state) do old, _\n    H(S(old))\nend];\n\nNow we can plot the readout statistics by partially tracing out the coin, and plotting the diagonal. The following is a walk on 61 nodes.\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.1: Probability distribution of a Quantum Walker in time\n\n\n\n\n\n\n\n\n\nQuantum Walks are not random\n\n\n\nNote, this is a single walker, not an ensemble of walkers as is the case in classical random walks. Quantum walks (without measurement), are completely deterministic.\n\n\n\n\n2.3.2 Circuit Formalism\nWhile the matrix definition of the Quantum Walks are easy to formalize and understand, finally these need to be simulated on some sort of device which may require us to reformulate it. Further, we try to ensure that the reformulation allows for easy additions of other dynamics which we may want to study.\nThe advantages of using a Quantum Computer over a classical computer for a quantum walk should be obvious. The problem however is that the quantum walk is over a high dimensional space, and we rarely have access to such high dimensional systems which we can control easily. Instead we need to simulate such a system using the accessible 2 level systems available in quantum computers.\nLet us define the basic components of our walk.\n\n2.3.2.1 Nodes\n\nEach numbered node is then converted into its 2-ary \\(n\\) length representation denoted by \\((x_i)\\). \\(n\\) is chosen such that \\(2^n\\) &gt; \\(N\\)\nThese bitstrings are encoded into an \\(n\\) qubit computer, where each basis state in the computational basis corresponds to the node with the same bitstring.\nThe amplitude of a particular basis corresponds to the amplitude of the walker in the corresponding node\n\n\n\n2.3.2.2 Coin\n\nThe Walk Coin is a two level system, as usual\n\n\n\n2.3.2.3 Edges and Shifts\n\nSince shifts are only to adjacent nodes, the left (right) shift is equivalent of subtracting (adding) 1 from the bitstring of the state.\nFrom the Quantum adder circuit, we can set one input to be \\((0)_{n-1}1\\) and reduce the circuit to get the Quantum AddOne circuit. Shown below is the circuit for \\(n=4\\) \\((N=16)\\)\nWe can similarly construct the SubOne circuit, but that is simplified by noting that the SubOne circuit is simply the inverse of the AddOne circuit, and this corresponds to just inverting the circuit (all gates are unitary).\n\n\nrightshift(n) = chain(\n    n, \n    map(n:-1:2) do i\n        control(1:i-1, i=&gt;X) end..., \n    put(1=&gt;X)\n)\nleftshift(n) = rightshift(n)';\n\n\nYaoPlots.plot(rightshift(4))\n\n\n\n\nFigure 2.2: Right shift circuit\n\n\n\n\n\nYaoPlots.plot(leftshift(4))\n\n\n\n\nFigure 2.3: Left shift circuit\n\n\n\n\nThe controlled shift operation is encoded as\n\nshift(n) = chain(n+1,\n    control(1, 2:n+1 =&gt; rightshift(n)),\n    put(1 =&gt; X),\n    control(1, 2:n+1 =&gt; leftshift(n)),\n    put(1 =&gt; X),\n)\n\nYaoPlots.plot(shift(4))\n\n\n\n\nFigure 2.4: Controlled shift circuit\n\n\n\n\n\n\n2.3.2.4 Coin operator\nWe can add the coin operator as usual on the first rail.\n\ncoin(n, c=Yao.H) = chain(n+1, put(1 =&gt; c))\nYaoPlots.plot(coin(4))\n\n\n\n\nFigure 2.5: Coin Operator circuit\n\n\n\n\n\n\n2.3.2.5 Evolve Circuit\nPutting these together, we get the operation for a single step of the evolution as below. Note that the top qubit rail is that of the coin, and the rest are those of the simulation of the system.\nThis circuit can be repeated to acheive any number of steps.\n\nevolve(n) = shift(n) * coin(n)\nYaoPlots.plot(evolve(4))\n\n\n\n\nFigure 2.6: Quantum walk evolve circuit\n\n\n\n\n\n\n2.3.2.6 Prepare circuit\nWhile we can already simulate the walk, an very useful helper function that we can define is the prepare circuit.\nQuantum registers are often initialized to the 0 state, and it is also easy to restart the walk from the 0 state. However, we often like to start the walk in the center of the chain instead of at node 0. Also, the coin is prefered to be in the \\(\\frac{1}{\\sqrt2}(|0\\rangle + i |1\\rangle)\\) when we start so that the walk proceeds symmetrically1.\nHence, to perform these steps, we define the following prepare subroutine.\n\nprepare(n) = chain(\n    n+1, \n    put(1=&gt;Yao.H), \n    put(1=&gt;Yao.shift(-π/2)), \n    put(n+1=&gt;X)\n)\n\nYaoPlots.plot(prepare(3))\n\n\n\n\nFigure 2.7: Initial state preparation circuit\n\n\n\n\nPlotting the walker distribution as before (Figure 2.8), we see that the two implementations are equivalent.\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.8: Quantum walk using circuit formalism"
  },
  {
    "objectID": "quantum.html#properties-of-the-walk",
    "href": "quantum.html#properties-of-the-walk",
    "title": "2  Quantum Walks",
    "section": "2.4 Properties of the walk",
    "text": "2.4 Properties of the walk\nSimilar to the classical random walk, the mean \\(\\mu(t) = 0\\).\nHowever, a more interesting feature is that the standard deviation \\(\\sigma(t) = 0.54 t\\)1. Compare this with the classical random walk, the quantum walk has a quadratic speed up. This the reason for the quadratic speedup commonly seen in the Grover search and other Monte Carlo problems.\n\n\n\nStandard Deviation with time for the quantum(crosses) and classical random(circles) walks\n\n\n\n\n\n\n\n\n1 R. Portugal, Quantum Walks and Search Algorithms, 2nd ed. 2018 (Springer International Publishing : Imprint: Springer, Cham, 2018)."
  },
  {
    "objectID": "search.html#formalism",
    "href": "search.html#formalism",
    "title": "3  Search Algorithms",
    "section": "3.1 Formalism",
    "text": "3.1 Formalism\nDefine the following\n\nDenote the readout at the \\(n^{\\text{th}}\\) measurement (at \\(t=n\\tau\\)) as \\(X_n\\).\nSelect a target node \\(\\delta\\)\nProbability of first hit in \\(n\\) steps \\(F_n = P(X_n = \\delta | X_i \\ne \\delta \\forall i \\in [0, n-1])\\)\nMean hit time \\(\\langle t_S \\rangle = \\sum_{i=0}^\\infty i F_i\\)\nSuccess probability in \\(n\\) steps \\(S_n = \\sum_{i=1}^{n}F_i = P(\\exists i \\in [0, n]| X_i = \\delta)\\)\nSurvival probability \\(=\\) Failure probability \\(= \\mathcal{S}_n = 1 - S_n\\)\nAsymptomatic versions of these terms are given by taking \\(n\\to \\infty\\)\n\n\n3.1.1 Readout in Walks\nTo identify whether a walker has hit the target node, we need to track the location of the walker as it evolves in time.\nFor the classical case, this poses no problem, as measurement does not disturb the system. In the quantum case however, we need to be a bit more careful.\nA constantly measured walker will freeze the dynamics of a quantum walker. This is known as the Quantum Zeno effect. The solution for this is to measure after every \\(\\tau\\) steps.\n\n\n\n\n\n\nReduction to classical random walk with \\(\\tau=1\\)\n\n\n\nThe quantum \\(\\tau = 1\\) case reduces the discrete time quantum walk to a classical random walk with \\(\\tau=1\\). Effectively, we apply a dephasing operator on the density matrix, dropping all off diagonal terms. Thus, we lose all effects of superposition, causing the classical random walk.\n\n\nLet us plot the readout trajectories of walkers with different parameters\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.1: Trajectories of readouts in quantum and classical walks\n\n\n\nNote the very clear difference in the spread between the classical readout and the quantum readout for same \\(\\tau\\). Similarly note the spread between the quantum readouts for different \\(\\tau\\)s."
  },
  {
    "objectID": "search.html#markov-chains-and-walks",
    "href": "search.html#markov-chains-and-walks",
    "title": "3  Search Algorithms",
    "section": "3.2 Markov Chains and Walks",
    "text": "3.2 Markov Chains and Walks\nIn the classical case, it is clear that the 1D SSRW is a Markov process. In Appendix B, we show that the quantum walk with measurement is also a Markov process. Consequently, we can use certain results from the theory of Markov processes to compare the two walks.\n\n3.2.1 Irreducibilty and Recurrence\nUnder the usual definition of irreducibility (Appendix A), it is trivial that in the 1D chain, \\(n = m = |i-j|\\tau\\) satisfies the condition. It is a well known fact that the 1D SSRW is recurrent. It is just as well known a fact that the 3D SSRW is transient1.\nIn the quantum case, it is not as clear whether any of the available definitions of the quantum Markov process is more or less better than the others. Thus, the transience of quantum walks depends on the exact definition we are working under2. In our definition however, it can be shown using symbolic computation3 that the walk is indeed transient. This poses an interesting problem."
  },
  {
    "objectID": "search.html#survival-probability",
    "href": "search.html#survival-probability",
    "title": "3  Search Algorithms",
    "section": "3.3 Survival probability",
    "text": "3.3 Survival probability\nWe can thus measure and plot the \\(S_n - n\\) curve for the quantum and classical walks to compare the efficiency of these walks in the first hit problem.\nIn previous work4, the analytical solution of the success rate as a function of time is found. An analytical result for discrete time walks is harder due to the nature of the walk. However we reproduce the results for the discrete time case computationally. Figure 3.2 (a)4 shows the success rate for the continuous time quantum and classical walks, and Figure 3.2 (b) and Figure 3.2 (c) shows our results for the discrete time case.\n\n\n\n\n\n\n\n(a) Success probability vs Time for both walks4\n\n\n\n\n\n\n\n\n\n(b) Success probability vs Time for both walks \\(\\tau=4\\)\n\n\n\n\n\n\n\n(c) Success probability vs Time for both walks \\(\\tau=8\\)\n\n\n\n\nFigure 3.2: Success Probability\n\n\n\n3.3.1 Observations\nIn the continuous time case:\n\nThe quantum walk has a fast rise in the initial phase but saturates at ~0.1\nThe classical walk has a slow rise, but eventually reaches 1\n\nIn the discrete time case, solved computationally:\n\nBoth walks do eventually reach 1\nThe quantum walk shows a saturation for a while before suddenly rising again\nThe classical walk shows a slow rise in the beginning phases, in contrast to the sharper rise of the quantum walk.\n\nThe observations in the continuous time case can be explained by the recurrence of the walk. While the quantum walker is faster (See Chapter 2), the transient nature (See Section 3.2.1) of the walk leads to a non zero asymptomatic failure rate. Clearly this is a problem. What this means practically, is that for the first hit problem, if the quantum walk hits the target node, it does so faster than the classical walk, but a majority of the times, it doesn’t hit the target node at all.\nThere seems to be an apparent difference between the discrete and the continuous time walks, but this is only an artifact of the finite size of the walk space. It is well known that any irreducible finite chain is recurrent5. This claim can be verified by simply increasing the size of the state space, and noting that the saturation phase in the quantum walk lasts longer.\n\n\n\n\n\n\n1 J.R. Norris, Markov Chains, 1st pbk. ed (Cambridge University Press, Cambridge, UK ; New York, 1998).\n\n\n2 M. Štefaňák, I. Jex, and T. Kiss, Physical Review Letters 100, 020501 (2008).\n\n\n3 H. Friedman, D.A. Kessler, and E. Barkai, Phys. Rev. E 95, 032141 (2017).\n\n\n4 R. Yin and E. Barkai, (2022).\n\n\n5 user940, (n.d.)."
  },
  {
    "objectID": "reset.html#formalism",
    "href": "reset.html#formalism",
    "title": "4  Stochastic Resetting",
    "section": "4.1 Formalism",
    "text": "4.1 Formalism\nA reset of the walker (classical or quantum) implies that the walker returns to its initial state, and the walk dynamics continue from there.\nHowever, we can vary when we reset the walker by considering multiple reset processes. A common reset process is the Poisson reset, where the reset times are modelled as a Poisson process with some parameter \\(r\\). This is particularly convenient in the case of continuous time walks1.\nFor the discrete walks, the geometric distribution is more natural. \\[t \\sim \\text{Geom}(\\gamma)\\], that is, at each step, there is a \\(\\gamma\\) probability of reset. This results in different dynamics, which can be seen in subsequent subsections, but it has an equally drastic effect on the recurrence of the walk.\n\n4.1.1 Recurrence and Resetting\nIn the geometric resetting case, it is clear that \\(P^n_{00} \\ge \\gamma\\), and hence \\(\\sum_n P^n_{00} \\ge \\sum_n \\gamma\\) which diverges as \\(n \\to \\infty\\). Thus regardless of the initial walk, the final walk will definitely be recurrent. Thus the motivation for resetting the quantum walk which is transient should be immediately clear.\n\n\n4.1.2 Stochastic Reset Classical Walk\nIn the classical case, the transition probabilities change to\n\\[p_{ij} = \\begin{cases}\n    (1-\\gamma) \\cdot 1/2 & |i - j| = 1 \\\\\n    \\gamma & j = r_0 \\\\\n    0 & \\text{otherwise}\n\\end{cases}\\]\nThus, the new transition matrix is modelled as\n\nγ = 0.2\nU1 = sparse(SymTridiagonal(fill(0., 31), fill(0.5, 30)))\nR = fill(0., (31, 31))\nR[21,:] .= 1\nU = sparse((1-γ) * U1 + γ * R);\n\nwhere U1 is the unchanged walk matrix and R is the reset matrix.\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4.1: Stochastic Reset Classical Walk\n\n\n\n\n\n4.1.3 Stochastic Reset Quantum Walk\nIn the quantum case, the evolution changes from unitary dynamics to a non-unitary CPTP map of the following form.\n\\[O_{SR}(\\rho) = (1-\\gamma)\\left(U\\rho U^\\dagger\\right) + \\gamma |r_0\\rangle\\langle r_0|\\]\nwhere \\(U\\) is the walk unitary.\n\nfunction swqw(n, γ)\n    R = collect(Tridiagonal(fill(1., n), zeros(n+1), zeros(n)))\n    R[1, end] = 1\n    L = collect(Tridiagonal(zeros(n), zeros(n+1), fill(1., n)))\n    L[end, 1] = 1\n    U = KrausOperators(\n        [sparse(proj(ket(1, 2)) ⊗ L + proj(ket(2, 2)) ⊗ R)]\n    )\n    init_coin = 1/√2 * (ket(1,2) - 1im * ket(2,2))\n    H = KrausOperators([sparse(hadamard(2)⊗I(n+1))])\n    init_state = proj(init_coin ⊗ ket(n÷2 + 1, n+1))\n    ψ = [[init_state]; accumulate(1:40, init=init_state) do old, _\n        (1-γ)*H(U(old)) + γ*proj(init_coin ⊗ ket(n÷2+6, n+1))\n    end]\n    map(enumerate(real.(diag.(ptrace.(\n        ψ, Ref([2, n+1]), Ref([1])\n    ))))) do (t, ps)\n        Plots.plot(\n            -n÷2:n÷2, ps, \n            ylims=(0, 1), xlabel=\"\\$i\\$\", \n            ylabel=\"\\$\\\\langle i|\\\\psi\\\\rangle\\$\",\n            title=\"\\$t=$(t), \\\\gamma=$(γ), r_0 = |5\\\\rangle \\$\",\n            legend=false\n        )\n    end\nend;\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4.2: Stochastic Reset Quantum Walk"
  },
  {
    "objectID": "reset.html#effect-of-resetting-on-first-hit-problem",
    "href": "reset.html#effect-of-resetting-on-first-hit-problem",
    "title": "4  Stochastic Resetting",
    "section": "4.2 Effect of Resetting on First Hit problem",
    "text": "4.2 Effect of Resetting on First Hit problem\nFor this analysis, we will consider the simpler “sharp reset” formalism2, where the reset time is sampled from a distribution\n\\[t_r \\sim \\delta(t-r\\tau)\\]\nThus we restart after \\(r\\) measurement events (at \\(t = r\\tau\\)). Once we understand the effect of this kind of reset, gaining intuition for reset times sampled differently is easier.\nThe success probability versus time can now be plotted (Figure 4.3 (a))2 for the reset case.\nNow we see that the success probability is drastically increased for both cases, but due to the ballistic nature of the quantum walk, we see that the reset quantum walk performs much better than the classical walk.\nFor a better understanding of the performance of the reset quantum walk with reference to changing reset rates (\\(r\\)) and measurement times (\\(\\tau\\)), we can plot (Figure 4.3 (b))2 the mean first hitting time versus these parameters.\n\n\n\n\n\n\n\n(a) Reset Success probability vs Time2\n\n\n\n\n \n\n\n\n\n\n(b) Effect of \\(r\\) and \\(\\tau\\) on mean hitting time2\n\n\n\n\nFigure 4.3: Sharp Reset Quantum Walk\n\n\n\n4.2.1 Observations\n\nDeterministic restart leads to zero asymptomatic failure rate\nEager restarting leads to walker never reaching \\(\\delta\\), reducing success rates drastically\nCautious restart reduces the effect of restart, reducing success rates.\nThere exists an optimal \\(r\\), but this needs to be optimized, which is non trivial for general \\(\\tau\\) and graph structures.\n\n\n\n\n\n\n\nCan stochastic restarting be better than sharp reset?\n\n\n\nNo, because even if \\(\\langle r\\rangle = r_{\\text{optimal}}\\), \\(\\langle t_f\\rangle &gt; \\langle t_f\\rangle_{\\text{optimal}}\\) due to the non-monotonic nature of the curve"
  },
  {
    "objectID": "reset.html#sharp-reset-for-discrete-time-walks",
    "href": "reset.html#sharp-reset-for-discrete-time-walks",
    "title": "4  Stochastic Resetting",
    "section": "4.3 Sharp Reset for Discrete time walks",
    "text": "4.3 Sharp Reset for Discrete time walks\nFor discrete time walks, the sharp reset walk is given by\n\\[|\\psi_t\\rangle = U^{t - r_l\\tau} (|c_\\text{init}\\rangle \\otimes |0\\rangle)\\]\nwhere \\(r_l \\tau\\) was the time of last reset.\nEquivalently, in the circuit model, the reset circuit is considered to be a measure followed by post process where we apply the appropriate unitary rotation to rotate to \\(|\\psi_0\\rangle\\).\n\n\n\n\n\n\n\nP(hit) vs Time\n\n\n\n\n\n\n\n\\(\\langle T_{hit}\\rangle\\) vs \\(\\gamma\\)\n\n\n\n\nFigure 4.4: Sharp Reset Quantum Walk - Multiple Sampling\n\n\n\n\n\n\n\n\n\nP(hit) vs Time \\(\\tau=4\\)\n\n\n\n\n\n\n\n\\(\\langle T_{hit}\\rangle\\) vs \\(\\gamma\\) \\(\\tau=4\\)\n\n\n\n\n\n\n\n\n\nP(hit) vs Time \\(\\tau=8\\)\n\n\n\n\n\n\n\n\\(\\langle T_{hit}\\rangle\\) vs \\(\\gamma\\) \\(\\tau=8\\)\n\n\n\n\nFigure 4.5: Sharp Reset Quantum Walk - Smooth Sampling\n\n\nOur results are plotted in Figure 4.4 where the circuit formalism is run multiple times, and in Figure 4.5, we pick the diagonal term from the matrix formalism as the infinite limit. Note the similarity between the continuous and discrete curves. However, also note the difference between the non reset curve, where in the discrete case, success probability still reaches 1, this can be attributed, as before, to the finiteness of the walk space."
  },
  {
    "objectID": "reset.html#the-problem-in-the-solution",
    "href": "reset.html#the-problem-in-the-solution",
    "title": "4  Stochastic Resetting",
    "section": "4.4 The Problem in the Solution",
    "text": "4.4 The Problem in the Solution\nAs discussed before, reset rates which are very high or low can end up being detrimental to the success times of the walk. Secondly, there is no clear path as to how to optimize the reset parameter for arbitrary graph structures.\nJust as we harnessed the power of quantum superposition to speed up the walk, can we similarly have a superposition between the reset and evolution to increase the efficiency of hitting a node?\n\n\n\n\n\n\n1 A. Srivastava, Resetting Quantum Systems Through Superposition of Evolution , PhD thesis, IISER Mohali, 2021.\n\n\n2 R. Yin and E. Barkai, (2022)."
  },
  {
    "objectID": "qreset.html#sec-qreset-formalism",
    "href": "qreset.html#sec-qreset-formalism",
    "title": "5  Quantum Resetting by Superposition",
    "section": "5.1 Formalism",
    "text": "5.1 Formalism\nOn a finite 1D chain of length \\(2N + 1\\), define the following -\n\nReset operation - \\(\\mathcal{R}\\) by the Kraus operators \\(\\{\\mathcal{R_i} = |r_0\\rangle\\langle i|\\}_{i\\in [-N, N]}\\) on \\(\\mathcal{H}_W\\)\nEvolve operation - \\(\\mathcal{U}\\) by the unitary operation \\(S\\circ H\\) on \\(\\mathcal{H}_C\\otimes\\mathcal{H}_W\\)\nAttach another two level coin - states denoted by \\(|0\\rangle\\) and \\(|1\\rangle\\). Resulting state lies in \\(\\mathcal{H}_R\\otimes\\mathcal{H}_C\\otimes\\mathcal{H}_W\\)\nControlled reset operation - \\(\\mathcal{E}\\) by the Kraus operators \\(\\{\\mathcal{E}_i = |0\\rangle\\langle 0|\\otimes I_2 \\otimes \\mathcal{R}_i + \\frac{1}{\\sqrt N} |1\\rangle\\langle 1|\\otimes \\mathcal{U}\\}_{i\\in [-N, N]}\\). See Appendix C for proof that this set of Kraus operators represents a CPTP map.\nA reset coin operator \\(\\Gamma(\\gamma) = \\begin{bmatrix}\\sqrt{1-\\gamma} & \\sqrt{\\gamma} \\\\ \\sqrt{\\gamma} & -\\sqrt{1- \\gamma}\\end{bmatrix}\\) on \\(\\mathcal{H}_R\\)\nOne step of the resulting walk is defined as \\(\\mathcal{E} \\circ \\left(\\Gamma \\otimes I_2 \\otimes I_{2N+1}\\right)\\)\nOnce again, the hitting protocol is found by measuring the walker position after \\(\\tau\\) time steps.\n\nThe initial motivation for such a formalism comes from Anubhav’s1 master thesis, where a similar formalism was applied to a qubit system. The dominant motivation is the faster convergence in the quantum case, which was confirmed in the qubit case. However, the current problem we are considering has drastically changed the methods of exploration and the property we want to optimize.\n\n5.1.1 Interpretation of \\(\\gamma\\) and dependence on initial condition of the coin\nIn the stochastic resetting \\(\\gamma\\) is understood as the “rate” of resetting. However, this is no longer accurate for the quantum case. Consider the case for \\(\\gamma = 0\\). Then, the Gammamard operator \\(\\Gamma = \\begin{bmatrix}1 & 0\\\\ 0 & -1\\end{bmatrix}\\). This does not automatically imply that the reset never occurs; we also require that the initial state of the reset coin is \\(|0\\rangle\\). If the initial state of the reset coin is \\(|1\\rangle\\), this corresponds to the always reset case. Thus, \\(\\gamma\\) is better understood as the probability that given the last step was a reset, what is the probability this step is an evolve, and vice versa. Thus, it is not immediately obvious how we can compare the reset mechanisms for a given \\(\\gamma\\). Nor is it obvious how the initial state of the reset coin finally affects the success probability and such, and needs to be numerically checked.\n\n\n5.1.2 Resetting of the walker coin\nIn our specific formalism (Section 5.1), we have only applied the reset operation on the walker \\(\\mathcal{H}_W\\). One could also reset the walker coin \\(\\mathcal{H}_C\\) and see what happens. In our current formalism, there is no entanglement broken between the two coins, but there is no a priori understanding of how this may (or may not) affect the walk."
  },
  {
    "objectID": "qreset.html#computational-implementation",
    "href": "qreset.html#computational-implementation",
    "title": "5  Quantum Resetting by Superposition",
    "section": "5.2 Computational Implementation",
    "text": "5.2 Computational Implementation\nImplementations of \\(\\mathcal{U}, U, H\\) follow as before. The \\(\\mathcal{E}\\) operation is implemented as\n\nfunction €(n, r₀)\n    ks = map(1:n) do i\n        (1/√n * [1 0; 0 0] ⊗ (S(n)*H(n))) +\n        [0 0; 0 1] ⊗ I(2) ⊗ real(ket(r₀,n)*bra(i,n))\n    end\n    return KrausOperators(sparse.(ks))\nend;\n\nThe gammamard operation \\(\\Gamma\\) is defined as\n\nΓ(γ) = [\n    √(1-γ)  √γ;\n    √γ      -√(1-γ)\n];\n\nWe take the initial reset coin to be \\((S(-\\pi/2)\\circ\\Gamma(\\gamma))|0\\rangle\\) for the same reason as in the quantum walk\n\nreset_init(γ) = [1 0; 0 -1im]*gammamard(γ)*ket(1, 2);"
  },
  {
    "objectID": "qreset.html#results",
    "href": "qreset.html#results",
    "title": "5  Quantum Resetting by Superposition",
    "section": "5.3 Results",
    "text": "5.3 Results\n\n5.3.1 What the walk looks like\nFor the specific choice of initial reset coin as \\(1/\\sqrt{2}\\left(|0\\rangle - i|1\\rangle\\right)\\) and \\(\\gamma=0.2\\), the quantum reset walk looks like Figure 5.1.\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 5.1: Quantum Reset Walk"
  },
  {
    "objectID": "qreset.html#results-and-discussion",
    "href": "qreset.html#results-and-discussion",
    "title": "5  Quantum Resetting by Superposition",
    "section": "5.4 Results and Discussion",
    "text": "5.4 Results and Discussion\nAs discussed in Section 5.1.1, we need to vary the three parameters, \\((\\alpha, \\phi, \\gamma)\\), and see what happens. Thus we plot the success curves for a few sets of parameters (Figure 5.2), and find the minimum mean time of hit for each fixed parameter (Figure 5.3).\n\n\n\n\n\n\n\n(a) Parameter set 1\n\n\n\n\n\n\n\n(b) Parameter set 2\n\n\n\n\n\n\n \n\n\n\n\n\n(c) Parameter set 3\n\n\n\n\n \n\n\nFigure 5.2: Mean hitting time for some parameter sets.\n\n\n\n\n\n\n\n\n\n(a) \\(\\alpha\\) vs \\(\\phi\\)\n\n\n\n\n\n\n\n(b) \\(\\alpha\\) vs \\(\\gamma\\)\n\n\n\n\n\n\n \n\n\n\n\n\n(c) \\(\\phi\\) vs \\(\\gamma\\)\n\n\n\n\n \n\n\nFigure 5.3: Optimal values by fixing the other two parameters\n\n\nAs we can see, the mean time of hit even for the best set of parameters(within the ranges explored) is not better than the optimal time for the stochastic reset protocol.\n\n5.4.1 Optimal Parameter Values\n\n\nTable 5.1: Optimal Parameter Values\n\n\n\\(\\alpha\\)\n\\(\\phi\\)\n\\(\\gamma\\)\n\n\n\n\n\\(0.0\\)\n\\(0.0\\)\n\\(10^{-5}\\)\n\n\n\n\n\n\n5.4.2 Drawbacks of the Formalism\nThe drawback of this formalism is its complexity. Whereas when we defined a quantum walk with a unitary evolution, we now have a complicated CPTP map to analyse. The difficulty doesn’t only lie in analytical complexity, but also in simulations, where simulating the quantum reset quantum walk takes much longer. Due to this, we look for a simpler, more elegant model for quantum resetting, preferably one which is unitary supported by a formal protocol to analyse its efficacy.\n\n\n\n\n\n\n1 A. Srivastava, Resetting Quantum Systems Through Superposition of Evolution , PhD thesis, IISER Mohali, 2021."
  },
  {
    "objectID": "szegedy.html#generalized-coined-walks",
    "href": "szegedy.html#generalized-coined-walks",
    "title": "6  Quantum Markov Chains",
    "section": "6.1 Generalized Coined walks",
    "text": "6.1 Generalized Coined walks\nWhen we quantized walks in Chapter 2, we attached a 2 level coin whose states represented the selected edge, and by putting the coin into superposition, one can apply a superposition of jumps. We would like to quantize walks on arbitrary undirected graphs using the coined walk formalism.\nGraphs can be partitioned into two classes, Class 1 and 2, based of the chromaticity of the graph.\n\n\n\n\n\n\nEdge Chromaticity\n\n\n\nThe edge-chromaticity of a graph is the minimum number of colors that the edges can be colored with such that no two adjacent edges are similarly colored and is denoted by \\(\\rho(G)\\).\n\n\nBy Vizing’s theorem1, \\(\\Delta(G) \\le \\rho(G) \\le \\Delta(G)+1\\), where \\(\\Delta(G)\\) is the max degree of the graph.\nGraphs of Class 1 are those where \\(\\Delta(G) = \\rho(G)\\) and graphs of Class 2 are the others. Walks on Class 1 graphs can be quantized by the coin - position formalism similar to the one introduced in Chapter 2, whereas walks on Class 2 graphs can be quantized by a walk on the edges rather than the nodes2. However, we’re still restricted to undirected graphs."
  },
  {
    "objectID": "szegedy.html#szegedy-walks",
    "href": "szegedy.html#szegedy-walks",
    "title": "6  Quantum Markov Chains",
    "section": "6.2 Szegedy Walks",
    "text": "6.2 Szegedy Walks\nIt is known that discrete time Markov chains do not naturally quantize via the coin formalism3. Szegedy3 came up with a formalism to quantize symmetric irreducible Markov chains by using the bipartite double cover of the underlying graph. This was then generalized to ergodic chains by Magniez et al.4. What follows is a brief introduction to the generalized Szegedy walks.\n\n6.2.1 Formalism\nLet \\(P\\) be the transition matrix of a reversible Markov chain. Let \\(P^*\\) be the time reversed Markov chain of \\(P\\).\nFor a state \\(|\\psi\\rangle \\in \\mathcal{H}\\), let \\(\\Pi_\\psi = |\\psi\\rangle\\langle \\psi |\\). For a subspace \\(\\mathcal{K}\\) of \\(\\mathcal{H}\\) spanned by a set of mutually orthogonal states \\(\\{|\\psi_i\\rangle : i \\in I\\}\\), let \\(\\Pi_{\\mathcal{K}} = \\sum_{i\\in I}\\Pi_{\\psi_i}\\) be the projector onto \\(\\mathcal{K}\\) and \\(\\mathcal{R}_{\\mathcal{K}} = 2\\Pi_{\\mathcal{K}} - \\text{Id}\\) be a reflection through \\(\\mathcal{K}\\).\nLet \\(\\mathcal{A} = \\text{Span}(|x\\rangle|p_x\\rangle: x\\in X)\\) and \\(\\mathcal{B} = \\text{Span}(|p_y^*\\rangle|y\\rangle: y\\in Y)\\) be subspaces of \\(\\mathcal{H} = \\mathbb{C}^{|X|\\times |X|}\\), where\n\\[|p_x\\rangle = \\sum_{y\\in X}\\sqrt{p_{xy}} |y\\rangle;  |p_y^*\\rangle = \\sum_{x\\in X}\\sqrt{p_{yx}^*} |x\\rangle\\]\nwhere \\(p_{ij}, p_{ij}^* \\text{ are elements of }P, P^*\\text{ respectively}\\), and \\(X\\) is the set of nodes, \\(Y\\) is the set of nodes after duplication.\n\n\n\n\n\n\nQuantum Markov Chain\n\n\n\nThe quantized version of the Markov chain \\(P\\) is defined to be the unitary operation \\(W(P) = \\mathcal{R}_{\\mathcal{B}}\\mathcal{R}_{\\mathcal{A}}\\) and is called the Szegedy walk. Where defined, the Szegedy walk is equivalent to two steps of the Coined quantum walk5.\n\n\n\n\n\nFigure 6.2: Duplication Process on a graph2\n\n\n\n\n\n\n\n\nThe Discriminant matrix\n\n\n\nFor an ergodic Markov chain \\(P\\) with stable distribution \\(\\pi\\), we define\n\\[D(P) = \\text{diag}(\\pi)^{1/2} \\cdot P \\cdot \\text{diag}(\\pi)^{-1/2}\\]\nas the discriminant matrix.\n\n\n\n\n6.2.2 Properties\n\nOn \\(\\mathcal{A}+\\mathcal{B}\\), eigenvalues of \\(W(P)\\) that have non-zero imaginary part are \\(e^{\\pm 2i\\theta_1}, \\dots, e^{\\pm 2i\\theta_l}\\), with same multiplicity.\nOn \\(\\mathcal{A}\\cap\\mathcal{B}\\), \\(W(P)\\) acts as the identity. The left (and right) singular vectors of \\(D\\) with singular value 1 span this space.\nOn \\(\\mathcal{A}\\cap\\mathcal{B^\\perp}\\) and \\(\\mathcal{A^\\perp}\\cap\\mathcal{B}\\), the operator acts as \\(-\\text{Id}\\). The \\(\\mathcal{A}\\cap\\mathcal{B^\\perp}\\) (resp. \\(\\mathcal{A^\\perp}\\cap\\mathcal{B}\\)), is spanned by the set of left (resp. right) singular vectors of D\nW(P) has no other eigenvalues on \\(\\mathcal{A}+\\mathcal{B}\\); on \\(\\mathcal{A}^\\perp\\cap\\mathcal{B}^\\perp\\) it acts as \\(\\text{Id}\\)"
  },
  {
    "objectID": "szegedy.html#sec-qht",
    "href": "szegedy.html#sec-qht",
    "title": "6  Quantum Markov Chains",
    "section": "6.3 Szegedy Search or the Quantum Hitting Time",
    "text": "6.3 Szegedy Search or the Quantum Hitting Time\nOf the many ways to define the search algorithm (refer to Chapter 3 for an introduction) for Szegedy walks, we shall look at two protocols, one which is easy to understand and the other easy to analyse. The original paper by Szegedy3 proposed the following protocol -\n\nModify the classical Markov chain to make all the marked vertices sinks.\n\n\\[p^\\prime_{xy} = \\begin{cases}\np_{xy}, &x \\notin G\\\\\n\\delta_{xy}, &x \\in G\n\\end{cases}\\]\n\nDefine \\(W^\\prime(P)\\) as the quantum Markov chain by the usual protocol.\nDefine the initial state\n\n\\[|\\psi(0)\\rangle = \\frac{1}{\\sqrt{n}}\\sum_{\\substack{x\\in X\\\\ y \\in Y}}\\sqrt{p_{xy}}\\]\n\nFinally define the quantum hitting time such that \\[F(T) \\ge 1 - \\frac{g}{n}\\] where \\[F(T) = \\frac{1}{T+1}\\sum_{t=0}^{T}\\Big\\lVert |\\psi(t)\\rangle - |\\psi(0)\\rangle\\Big\\rVert^2; g = |G|\\]\n\n\n\n\nFigure 6.3: Duplication Process of a graph with marked vertex \\(x_3\\)2\n\n\nDefined by this protocol, the quantum hitting time is quadratically smaller than the classical hitting time3 for the 1D case.\nA later modification4 defined the search operation via a Grover-like oracle. This was easier to analyse, and the connection between the spectral gap of the discriminant matrix (Section 6.2.1) and the quadratic speedup attained by the walk is clearer. We leave the exact protocol to reference4, but only outline the steps.\n\nPrepare the initial state \\(|\\pi\\rangle|0^Tks\\rangle\\), where \\[|\\pi\\rangle_d = \\sum_{x\\in X} \\sqrt{\\pi_x}|x\\rangle |p_x\\rangle = \\sum_{y\\in X} \\sqrt{\\pi_x}|x\\rangle |p_x\\rangle\\]\nFirst apply the Grover oracle \\[\\mathcal{G}(|x\\rangle_d|y\\rangle_d |z\\rangle) = \\begin{cases}-|x\\rangle_d|y\\rangle_d|z\\rangle, & \\text{if } x \\in G\\\\+|x\\rangle_d|y\\rangle_d|z\\rangle, & \\text{otherwise}\\end{cases}\\]\nApply a phase estimation circuit to the quantum walk, repeated \\(k\\) times.\nRepeat steps 2 and 3 \\(T\\) times.\nObserve the first register, by a projective measurement in the computational basis. Denote by \\(\\bar{x}\\)\nWith high probability, output \\(\\bar{x}\\) lies in \\(G\\)\n\nIf the eigenvalue gap of the Markov chain is \\(\\delta\\), and \\(\\frac{|G|}{N} \\ge \\epsilon \\ge 0\\), the cost to perform this circuit is of order \\(\\left(\\frac{1}{\\sqrt{\\epsilon\\delta}} \\log \\frac{1}{\\sqrt \\epsilon}\\right)\\) calls to the walk operation4. Contrast this with the classical search which requires \\(\\frac{1}{\\delta\\epsilon}\\) steps of the Markov walk, we see the quadratic speedup 1.\nTherefore, one can find the spectral gap \\(\\delta\\) of \\(P\\) and compare the search speed of two chains. This Szegedy formalism beautifully sets up the stage for a truly unitary quantum reset quantum walk protocol which can be analysed for any graph structure without having to resort to simulation techniques.\n\n\n\n\n\n\n1 Wikipedia contributors, (2023).\n\n\n2 R. Portugal, Quantum Walks and Search Algorithms, 2nd ed. 2018 (Springer International Publishing : Imprint: Springer, Cham, 2018).\n\n\n3 M. Szegedy, in 45th Annual IEEE Symposium on Foundations of Computer Science (IEEE, Rome, Italy, 2004), pp. 32–41.\n\n\n4 F. Magniez, A. Nayak, J. Roland, and M. Santha, SIAM Journal on Computing 40, 142 (2011).\n\n\n5 T.G. Wong, Quantum Information Processing 16, 215 (2017).\n\n\n6 H. Krovi, F. Magniez, M. Ozols, and J. Roland, Algorithmica 74, 851 (2016)."
  },
  {
    "objectID": "szegedy.html#footnotes",
    "href": "szegedy.html#footnotes",
    "title": "6  Quantum Markov Chains",
    "section": "",
    "text": "Technically, this is not a quadratic speedup due to the extra \\(\\log\\frac{1}{\\epsilon}\\) term, and it was only later shown6 using a protocol of eigenvalue estimation.↩︎"
  },
  {
    "objectID": "uqreset.html#ergodicity-of-the-stochastic-reset-classical-walk",
    "href": "uqreset.html#ergodicity-of-the-stochastic-reset-classical-walk",
    "title": "7  Unitary Quantum Reset Quantum Walk",
    "section": "7.1 Ergodicity of the Stochastic Reset Classical Walk",
    "text": "7.1 Ergodicity of the Stochastic Reset Classical Walk\n\n\n\n\n\n\n  \n    \n  \n\n\n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n\n\n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n\n\n\n\n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n\n\n  \n    \n      -5\n    \n  \n  \n    \n      -4\n    \n  \n  \n    \n      -3\n    \n  \n  \n    \n      -2\n    \n  \n  \n    \n      -1\n    \n  \n  \n    \n      0\n    \n  \n  \n    \n      1\n    \n  \n  \n    \n      2\n    \n  \n  \n    \n      3\n    \n  \n  \n    \n      4\n    \n  \n  \n    \n      5\n    \n  \n\n\n\nGraph of the Stochastic Reset Classical Walk\n\n\nTo show ergodicity, we need to show that the walk is irreducible, aperiodic and positive recurrent.\nIrreducibility follows from the irreducibility of the 1D walk (Appendix A) \\(\\forall \\gamma &lt; 1\\). For the trivial case of \\(\\gamma = 1\\), the chain is not irreducible, and we cannot use the Szegedy formalism.\nAperiodicity (Appendix A) of the chain follows from the irreducibility of the chain and aperiodicity of node \\(0\\) which is obvious due to the existence of the self loop.\nRecurrence is obvious from \\(p_{00}^{(n)} \\ge \\gamma \\forall i\\) and irreducibility. Positive recurrence is harder to show, but we can solve the recurrence relation (Chapter 5).\nThus, the stochastic reset classical walk is ergodic and is a viable candidate for quantization via the Szegedy walk."
  },
  {
    "objectID": "uqreset.html#implementation-and-results",
    "href": "uqreset.html#implementation-and-results",
    "title": "7  Unitary Quantum Reset Quantum Walk",
    "section": "7.2 Implementation and Results",
    "text": "7.2 Implementation and Results\nThe implementation of the Szegedy walk is simplified by the use of QuantumWalk.jl1 and LightGraphs.jl2\n\n\nWARNING: using Plots.gr in module Main conflicts with an existing identifier.\n\n\nFirst we define a function that returns the underlying graph and the transition matrix\n\nMyGraph(n, γ=0.5) =\n    let\n        temp = CycleGraph(n) |&gt; adjacency_matrix |&gt; collect\n        reset = zero(temp)\n        reset[:, n÷2] .= 1\n        stochastic = ((1 - γ) / 2) * temp + γ * reset\n        temp = sign.(temp + reset)\n        DiGraph(temp), sparse(transpose(stochastic))\n    end\n\nThen we define and run the search algorithm.\n\nfunction run_search_mygraph(n, δ, T, γ)\n    graph, stochastic = MyGraph(n, γ)\n    qwe = QWSearch(Szegedy(graph, stochastic), [n÷2 + δ])\n    first.(measure.(Ref(qwe), execute_all(qwe, T), Ref([n÷2 + δ])))\nend\n\nQuantumWalk.jl uses the Grover-like search algorithm3.\n\nstruct Simulation\n    n::Int64\n    δ::Int64\n    T::Int64\n    γ::Float64\n    data::Vector{Float64}\n    function Simulation(n, δ, T, γ)\n        new(n, δ, T, γ, run_search_mygraph(n, δ, T, γ))\n    end\nend\n\nmean_hit(s::Simulation) = mean(0:s.T, Weights(success(s)))\nsuccess(s::Simulation) = accumulate(s.data, init=0) do old, curr\n    (1-old) * curr + old\nend\n\nWe can scan over \\(\\gamma \\in [0, 1]\\) an plot the mean hit time.\n\nres = map(0:0.01:1) do γ\n    Simulation.(100, 10, 100, γ)\nend;\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Probability of measuring in \\(\\delta\\)\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Success Probability\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Mean hit time vs time\n\n\n\nFigure 7.1: Unitary Quantum Reset"
  },
  {
    "objectID": "uqreset.html#results-and-discussion",
    "href": "uqreset.html#results-and-discussion",
    "title": "7  Unitary Quantum Reset Quantum Walk",
    "section": "7.3 Results and Discussion",
    "text": "7.3 Results and Discussion\n\n7.3.1 Exceptional Quantum Walk on the Cycle\nFor the non reset (\\(\\gamma = 0\\)) case, we see that the success rate does not increase with time. While this is initially surprising, this is a known result4, caused due to the fact that the initial state evolves by phase flips, and the amplitude does not increase.\nIn the reset case, we see that the walk is no longer exceptional (at least, not in this sense), which allows for an amplitude amplification on the marked node.\n\n\n7.3.2 Mean hitting time vs \\(\\gamma\\)\nPlotting the mean hitting time versus time for \\(500\\) nodes and \\(500\\) steps, we get the curve in Figure 7.2.\n\n\n\nFigure 7.2: Unitary Quantum Reset\n\n\nAs we can see, there is a clear non-monotonous effect of \\(\\gamma\\) on the mean hitting time of the walk. For values a bit more than \\(\\gamma = 0.5\\), we see that the mean hitting time is much lower than that for the no reset \\(\\gamma = 0\\) case. Also of note is that as \\(\\gamma \\to 1\\) the mean hitting rate approaches that of the no reset case.\nNumerically, the exact time for mean hit changes according to the amount of time that we run the simulation for. This is obvious from the way that the mean hit time is calculated, where if the walk has not succeeded within the time of running the simulation, we assume that it succeeds in the next step. However, we recover the same qualitative curve for large number of steps.\n\n\n7.3.3 Eigenvalue analysis\nIn Section 6.3, we saw how the quadratic increase in the eigen-gap (\\(\\Delta P\\)) leads to an associated speedup in the search problem. Thus, if we can show that the eigen-gap increases in for the reset case, we can show that the search protocol requires fewer steps to complete. Furthermore, the space cost of the circuit goes as \\(\\left\\lceil \\log_2 \\left(\\frac{2\\pi}{\\Delta P}\\right)\\right\\rceil\\)\nWe see that the transition matrix is extremely sparse, especially for larger system sizes (goes as \\(\\mathcal{O}(3N)\\), so the density goes as \\(\\mathcal{O}(1/N)\\)), and that we do not require the entire eigen spectrum to find the eigen-gap. Thus, we can use specialized methods such as the Arnoldi method provided in Julia by the KrylovKit.jl5 package.\n\nusing KrylovKit\n\nfunction eigen_gap(M)\n    v = real(eigsolve(M, 2, :LR)[1]) # get real(eigval)\n    v[1] - v[2]\nend\n\nγs = 0.:0.01:(1-0.01)\n\nΔP = eigen_gap.(getindex.(MyGraph.(512, γs), 2))\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Eigen Gap\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Space complexity\n\n\n\nFigure 7.3: Analysis by Eigen Gap of the Reset Walk\n\n\nWe see that increasing \\(\\gamma\\) leads to an equal increase in \\(\\Delta P\\), which corresponds to a faster convergence. However, there is a competing loss of success probability, which is why we see a non monotonic curve for the mean hitting time against \\(\\gamma\\).\n\n\n\n\n\n\n1 A. Glos and J. Adam Miszczak, (2018).\n\n\n2 S. Bromberger and O. Contributors, (2017).\n\n\n3 T.G. Wong, Quantum Information Processing 16, 215 (2017).\n\n\n4 T.G. Wong and R.A.M. Santos, Quantum Information Processing 16, 154 (2017).\n\n\n5 Jutho and Contributors, (n.d.)."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "1 Jutho and\nContributors, (n.d.).\n\n\n2 T.G.\nWong and R.A.M. Santos, Quantum Information Processing\n16, 154 (2017).\n\n\n3 A. Glos\nand J. Adam Miszczak, (2018).\n\n\n4 H.\nKrovi, F. Magniez, M. Ozols, and J. Roland, Algorithmica\n74, 851 (2016).\n\n\n5 Wikipedia contributors, (2023).\n\n\n6 M.\nŠtefaňák, I. Jex, and T. Kiss, Physical Review Letters\n100, 020501 (2008).\n\n\n7 R. Yin and E.\nBarkai, (2022).\n\n\n8 user940,\n(n.d.).\n\n\n9 K.P.\nGriffin, S.J. Suresh, T.J. Flint, and W.H.R. Chan, (2019).\n\n\n10 M. Goldsmith, G.\nGarcía-Pérez, J. Malmi, M.A.C. Rossi, H. Saarinen, and S. Maniscalco,\n(2022).\n\n\n11 X. Bonnetain, A.\nChailloux, A. Schrottenloher, and Y. Shen, (2022).\n\n\n12 M. Szegedy,\nin 45th Annual IEEE Symposium\non Foundations of Computer\nScience (IEEE, Rome, Italy, 2004), pp. 32–41.\n\n\n13 S.A. Ortega and\nM.A. Martin-Delgado, (2022).\n\n\n14 H.\nFriedman, D.A. Kessler, and E. Barkai, Phys. Rev. E 95,\n032141 (2017).\n\n\n15 F. Magniez, A.\nNayak, J. Roland, and M. Santha, SIAM Journal on Computing\n40, 142 (2011).\n\n\n16 D.\nPsaltis, F. Özel, L. Medeiros, P. Christian, J. Kim, C. Chan, L.J.\nConway, C.A. Raithel, D. Marrone, and T.R. Lauer, ApJ\n928, 55 (2022).\n\n\n17 Qiskit, Quantum Walk Search Algorithm\n(n.d.).\n\n\n18 J.R. Norris, Markov Chains, 1st pbk. ed\n(Cambridge University Press, Cambridge, UK ; New York, 1998).\n\n\n19 P. Glasserman, Monte Carlo Methods in\nFinancial Engineering (Springer, New York, 2004).\n\n\n20 N. Metropolis, (n.d.).\n\n\n21 A. Srivastava, Resetting Quantum\nSystems Through Superposition of\nEvolution , PhD thesis, IISER Mohali, 2021.\n\n\n22 L.S.\nde Souza, J.H.A. de Carvalho, and T.A.E. Ferreira, in 2019 8th\nBrazilian Conference on\nIntelligent Systems (\nBRACIS) (IEEE, Salvador, Brazil, 2019), pp. 836–841.\n\n\n23 M. Bae\nand W.O. Krawec, (2021).\n\n\n24 S.\nMukherjee, IEEE Trans. Quantum Eng. 3, 1 (2022).\n\n\n25 X.-Z.\nLuo, J.-G. Liu, P. Zhang, and L. Wang, Quantum 4, 341\n(2020).\n\n\n26 T.\nBreloff, (2022).\n\n\n27 J. Bezanson,\nA. Edelman, S. Karpinski, and V.B. Shah, SIAM Rev. 59,\n65 (2017).\n\n\n28 P.\nGawron, D. Kurzyk, and Ł. Pawela, PLoS ONE 13, e0209358\n(2018).\n\n\n29\nJuliaGraphics, (n.d.).\n\n\n30 S.\nBromberger and O. Contributors, (2017).\n\n\n31 T.G.\nWong, Quantum Information Processing 16, 215\n(2017).\n\n\n32 R. Portugal, Quantum\nWalks and Search\nAlgorithms, 2nd ed. 2018 (Springer International\nPublishing : Imprint: Springer, Cham, 2018)."
  },
  {
    "objectID": "appendix-markov.html",
    "href": "appendix-markov.html",
    "title": "Appendix A — Markov Chains",
    "section": "",
    "text": "The following are some definitions related to Markov chains, which can be found in any introductory textbook to the topic1.\n\n\n\n\n\n\nDefinition: Connectivity\n\n\n\nStates \\(i, j \\in S\\), are connected if \\(\\exists n &gt; 0, m &gt; 0 | P^n_{ij} &gt; 0 \\text{ and } P^m_{ji} &gt; 0\\). Note that this is an equivalence relation.\n\n\n\n\n\n\n\n\nDefinition: Class\n\n\n\nIf \\(C \\subset S\\), and \\(C\\) is closed under Connectivity, then \\(C\\) is a closed connected class.\n\n\n\n\n\n\n\n\nDefinition: Irreducibility\n\n\n\nIf \\(\\nexists C | C \\subset S \\text{ closed under Connectivity}\\), \\(S\\) is a closed connected class.\n\n\n\n\n\n\n\n\nDefinition: Recurrence\n\n\n\nIf \\(i \\in S, \\sum_{n=1}^\\infty P^n_{ii} \\to \\infty\\), then the state is called recurrent. Equivalently, \\(\\sum_n F_n \\to 1\\) for recurrent nodes. If a chain is irreducible and one of its states is recurrent, all its states are recurrent and thus the chain is called recurrent.\n\n\n\n\n\n\n\n\nDefinition: Stopping time\n\n\n\nA random variable \\(T : \\Omega \\to {0, 1, ...} \\cup {\\infty}\\) is a stopping time the event \\(\\{T=n\\}\\) depends only on \\(X_0, X_1, \\dots X_n\\) for \\(n = 0, 1, 2, \\dots\\)\n\n\n\n\n\n\n\n\nDefinition: Periodicity\n\n\n\nFor a state \\(i \\in S\\), the Period is \\(\\gcd \\{n\\ge 0: p_{ii}^{(n)} &gt; 0\\}\\). If the Period of the state is 1, then it is called aperiodic. For an irreducible chain, if one state is aperiodic, then all states are aperiodic, and the chain is referred to as aperiodic.\n\n\n\n\n\n\n\n\nTime reversed Markov chain\n\n\n\nFor a Markov chain \\(P\\) with stable distribution \\(\\pi\\), \\(P^*\\) given by \\(p^*_{ji} = \\dfrac{\\pi_{i}p_{ij}}{\\pi_j}\\) is the transition matrix of the time reversed Markov chain.\n\n\n\n\n\n\n\n\nDefinition: Ergodic Markov chain\n\n\n\nFor a Markov chain \\(P\\) with stable distribution \\(\\pi\\), \\(P^*\\) given by \\(p^*_{ji} = \\dfrac{\\pi_{i}p_{ij}}{\\pi_j}\\) is the transition matrix of the time reversed Markov chain.\n\n\n\n\n\n\n\n\n1 J.R. Norris, Markov Chains, 1st pbk. ed (Cambridge University Press, Cambridge, UK ; New York, 1998)."
  },
  {
    "objectID": "appendix-meas-is-markov.html",
    "href": "appendix-meas-is-markov.html",
    "title": "Appendix B — Measured Quantum Walk is Markov",
    "section": "",
    "text": "Let \\(X_i\\) be the \\(i\\)th readout in the measured quantum walk protocol. This implies that immediately after the \\(i\\)th measurement, the state of the walker is \\(|X_i\\rangle\\). After \\(\\tau\\) steps, the walker is in state \\(E^{\\tau}|X_i\\rangle\\). The probability of measuring the walker in \\(X_{i+1}\\) is given by \\(|\\langle X_{i+1}| E^{\\tau}X_i\\rangle|^2\\). Thus \\(P(X_{i+1} = X_{i+1} | X_i, \\dots, X_0) = P(X_{i+1} = X_{i+1} | X_i)\\), which implies that the readouts in the measured quantum walk protocol is a Markov process."
  },
  {
    "objectID": "appendix-qreset.html",
    "href": "appendix-qreset.html",
    "title": "Appendix C — Quantum Reset is a CPTP map",
    "section": "",
    "text": "We prove that the set of Kraus operators defined in Chapter 5 form a CPTP map.\nWe are required to show that\n\\[\\sum_{i}\\mathcal{E}_i^\\dagger \\mathcal{E}_i = \\mathbf{1}\\]\nWe start by evaluating \\[\\mathcal{E}_i^\\dagger \\mathcal{E}_i = |0\\rangle\\langle 0|\\otimes I_2 \\otimes \\mathcal{R_i}^\\dagger \\mathcal{R_i} + \\frac{1}{N}|1\\rangle\\langle 1| \\otimes I_n = |0\\rangle\\langle 0|\\otimes I_2 \\otimes |i\\rangle\\langle i| + \\frac{1}{N}|1\\rangle\\langle 1| \\otimes I_n \\]\nSumming over \\(i\\)\n\\[\\sum_{i} \\mathcal{E}_i^\\dagger \\mathcal{E}_i = |0\\rangle\\langle 0 | \\otimes I_2 \\otimes I_n + |1\\rangle\\langle 1| \\otimes I_2 \\otimes I_n = I_{4n}\\]\nWe are done."
  }
]